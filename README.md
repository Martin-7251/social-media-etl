ğŸ“ŠSocial Media ETL Pipeline with Airflow, Docker & PostgreSQL
This project implements a complete ETL (Extract, Transform, Load) pipeline for social media data using Apache Airflow for orchestration and Docker to manage services like MongoDB, PostgreSQL, and MySQL.

ğŸš€ Features
âœ… Extracts raw JSON data from local files

ğŸ” Transforms user, post, comment, and like data using Pandas and NumPy

ğŸ“¥ Loads:

Users into MongoDB

Posts into PostgreSQL

Comments and likes into MySQL

ğŸ“… Scheduled with Apache Airflow (LocalExecutor)

ğŸ³ Fully containerized with Docker Compose

ğŸ§© Optional web UIs: pgAdmin, mongo-express

ğŸ“‚ Project Structure
bash
Copy
Edit
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ etl_dag.py
â”‚   â”‚   â”œâ”€â”€ extract_all_data.py
â”‚   â”‚   â”œâ”€â”€ transform_all_data.py
â”‚   â”‚   â””â”€â”€ load_to_postgres.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ User.json
â”‚   â”œâ”€â”€ posts.json
â”‚   â”œâ”€â”€ postComments.json
â”‚   â””â”€â”€ postLikes.json
â”œâ”€â”€ postgres/
â”œâ”€â”€ mysql/
â”œâ”€â”€ mongodb/
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md

âš™ï¸ Technologies Used
Tool                                                	Purpose
Apache Airflow                                       	Workflow orchestration
Docker	                                              Containerization of services
PostgreSQL	                                          Stores transformed post data
MongoDB	                                              Stores transformed user data
MySQL	                                                Stores comments and likes data
pgAdmin                                             	PostgreSQL web UI
Mongo Express                                       	MongoDB web UI
Pandas/NumPy	                                        Data cleaning and transformation

ğŸ§  ETL Workflow Overview
ğŸ”¸ 1. Extract
Raw JSON files (User.json, posts.json, postComments.json, postLikes.json)

Extracted and inserted into MongoDB, MySQL, PostgreSQL

ğŸ”¸ 2. Transform
Cleaned using Pandas & NumPy

Fixes formatting, data types, and missing values

ğŸ”¸ 3. Load
Transformed data loaded into:

users_cleaned (MongoDB)

posts_cleaned (PostgreSQL)

comments_cleaned, likes_cleaned (MySQL)

ğŸ³ How to Run (Local)
Ensure you have Docker + Docker Compose installed.

Clone the repository

bash
Copy
Edit
git clone https://github.com/your-username/social-media-etl.git
cd social-media-etl
Start all containers

bash
Copy
Edit
docker-compose up --build
Access Airflow

ğŸŒ http://localhost:8081

Username: admin, Password: admin

Trigger the DAG

Open Airflow UI

Turn on and trigger the DAG: Extract_transform_load

ğŸ›  Optional Admin Interfaces
pgAdmin: http://localhost:5050

Email: admin@admin.com, Password: admin

mongo-express: http://localhost:8083

Username: admin, Password: pass

admirer: http://localhost:8082

Username: airflow, Password: airflow

ğŸ“… DAG Schedule
DAG ID: Extract_transform_load

Runs every Wednesday at 12:00 PM (Africa/Nairobi timezone)

Can also be triggered manually


