# ğŸ§ª Social Media ETL Pipeline

This project is an end-to-end **ETL (Extract, Transform, Load)** pipeline for social media data, built using **Docker, Airflow, MongoDB, MySQL, PostgreSQL, and Python**.

It automates data ingestion from JSON files, transformation using Pandas and NumPy, and loads the cleaned data into structured databases for further analysis and visualization.

---

## ğŸ“ Project Structure

SOCIAL_MEDIA_ETL/
â”‚
â”œâ”€â”€ airflow/
â”‚ â””â”€â”€ dags/
â”‚ â”œâ”€â”€ data/ # Raw and transformed JSON data
â”‚ â”œâ”€â”€ extract_all_data.py # Extract data from files and load into DBs
â”‚ â”œâ”€â”€ transform_all_data.py # Transform raw data with pandas/NumPy
â”‚ â”œâ”€â”€ load_to_postgres.py # Load transformed data into PostgreSQL
â”‚ â””â”€â”€ etl_dag.py # Airflow DAG defining ETL pipeline
â”‚
â”œâ”€â”€ Dockerfile # Custom Airflow image with Python packages
â”œâ”€â”€ docker-compose.yml # Define all services (Airflow, DBs, etc.)
â”œâ”€â”€ ETL_Data_Visualizations.py # Standalone script for visualizing ETL data
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

## ğŸ› ï¸ Technologies Used

- **Airflow** â€“ Workflow orchestration
- **Docker & Docker Compose** â€“ Containerized setup
- **PostgreSQL, MySQL, MongoDB** â€“ Target databases
- **Pandas, NumPy** â€“ Data transformation
- **Matplotlib, Seaborn, Plotly** â€“ Visual analytics
- **VS Code / Python Scripts** â€“ Development and testing

---

## ğŸ” ETL Pipeline Overview

1. **Extract**  
   - Load raw `.json` data files from `dags/data/`
   - Insert into MongoDB (users), PostgreSQL (posts), MySQL (comments/likes)

2. **Transform**  
   - Clean, normalize, and derive new fields (e.g., follower/following ratio)
   - Save transformed data as new `.json` files

3. **Load**  
   - Insert transformed data into PostgreSQL

4. **Visualize**  
   - Analyze trends and patterns using `ETL_Data_Visualizations.py`

---

## ğŸš€ How to Run the Project

### 1. Clone the Repository
``bash
git clone https://github.com/Martin-7251/social_media_etl.git
cd social_media_etl

ğŸ³ How to Run (Local)
Ensure you have Docker + Docker Compose installed.

2. Start Docker Containers
bash
Copy
Edit
docker-compose up --build
3. Access Airflow UI
Navigate to http://localhost:8081 and trigger the Extract_transform_load DAG.

ğŸŒ http://localhost:8081

Username: admin, Password: admin

Trigger the DAG

Open Airflow UI

Turn on and trigger the DAG: Extract_transform_load

ğŸ›  Optional Admin Interfaces
pgAdmin: http://localhost:5050

Email: admin@admin.com, Password: admin

mongo-express: http://localhost:8083

Username: admin, Password: pass

admirer: http://localhost:8082

Username: airflow, Password: airflow

4. Run Visualizations (Optional)
bash
Copy
Edit
python ETL_Data_Visualizations.py
ğŸ“Š Sample Visualizations
Followers vs Following (scatter)

Account privacy distribution (pie chart)

Post likes over time (line chart)

Comments per post (histogram)

Top 10 most liked posts (bar chart)

ğŸ“Œ Future Improvements
Integrate with social media APIs for real-time data

Add unit tests and logging

Build interactive dashboards using Plotly Dash


Runs every Wednesday at 12:00 PM (Africa/Nairobi timezone)

Can also be triggered manually

## ğŸ‘¨â€ğŸ’» Author

- **Martin Kamau**  
  Data Analyst | Data Engineer | [LinkedIn](https://www.linkedin.com/in/martinkamau29/)


  




